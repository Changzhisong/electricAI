{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_score(predict, real):\n",
    "    f = (real - predict)/real\n",
    "    n = len(f)\n",
    "    f = f.replace([np.nan, -np.nan], 0)\n",
    "    score = 1 - np.abs(f).sum()/n\n",
    "    return score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if sys.argv[1] == 'test':\n",
    "    is_train = False\n",
    "    train_path = '../dataset/fetures/test.csv'\n",
    "    predict_path = '../dataset/fetures/test_predict.csv'\n",
    "    feture_path = '../dataset/fetures/test_feture.csv'\n",
    "    \n",
    "else:\n",
    "    is_train = True\n",
    "    if sys.argv[2].endswith('.json'):\n",
    "        month = '9'\n",
    "    else:\n",
    "        month = sys.argv[2]\n",
    "    train_path = '../dataset/fetures/{}/train.csv'.format(month)\n",
    "    predict_path = '../dataset/fetures/{}/train_predict.csv'.format(month)\n",
    "    feture_path = '../dataset/fetures/{}/train_feture.csv'.format(month)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path, parse_dates=['record_date'])\n",
    "predict = pd.read_csv(predict_path, parse_dates=['predict_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "end_date = train.record_date.max().date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_timespan(end_date, m_span):\n",
    "    predict_start = end_date + timedelta(1)\n",
    "    n_month = predict_start.month - m_span\n",
    "    if n_month < 1:\n",
    "        n_month = 12 + n_month\n",
    "        n_year = predict_start.year - 1\n",
    "    else:\n",
    "        n_year = predict_start.year\n",
    "    n_date = date(n_year, n_month, predict_start.day)\n",
    "    return (predict_start - n_date).days - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create_timespan(end_date, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_spans = [30, 60, 90, 180, 366]\n",
    "# time_spans = [30, 60, 90, 150, 180, 210, 270, 300, 366] # over fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for span in time_month_spans:\n",
    "#     time_spans.append( create_timespan(end_date, span) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 60, 90, 180, 366]\n"
     ]
    }
   ],
   "source": [
    "print(time_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "used_data_fetures = [\n",
    "    'dayofweek', 'dayofyear', 'days_in_month', 'quarter', 'week', 'weekofyear',\n",
    "    'month', 'year'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_df(date_span, train):\n",
    "    begin_date = end_date - timedelta(date_span)\n",
    "    train_df = train.set_index(['record_date']).loc[str(begin_date):str(end_date)].reset_index()\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_feture_in_date(used_feture, predict, train_df):\n",
    "    for f in used_data_fetures:\n",
    "        predict[f] = getattr(predict['predict_date'].dt, f)\n",
    "        train_df[f] = getattr(train_df['record_date'].dt, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_describe_feture(train_df, predict, f, date_span):\n",
    "    df = train_df.groupby(f).describe()['power_consumption'].unstack()\n",
    "    column_fmt = 'post{}_{}_{}'\n",
    "    df.columns = [column_fmt.format(date_span, f, x) for x in   df.columns]\n",
    "    predict = predict.join(df, on=f)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_post_day_describe(date_span, train, predict, used_data_fetures, add_feture=True):\n",
    "    train_df = get_train_df(date_span, train)\n",
    "    if add_feture:\n",
    "        add_feture_in_date(used_data_fetures, predict, train_df)\n",
    "    for f in used_data_fetures:\n",
    "        predict = extract_describe_feture(train_df, predict, f, date_span)\n",
    "    return predict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for date_span in time_spans:\n",
    "    predict = extract_post_day_describe(date_span, train, predict, used_data_fetures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 节假日特征 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_holiday_fetures = ['is_week', 'is_weekend', 'is_festival', 'is_holiday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  holiday\n",
       "0 2015-01-02        2\n",
       "1 2015-02-24        2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holiday_df = pd.read_csv('../dataset/holiday.csv', parse_dates=['date'])\n",
    "holiday_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holiday_df['is_holiday'] = 0\n",
    "\n",
    "holiday_df.loc[holiday_df.holiday!=0, 'is_holiday'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(holiday_df.holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns = ['is_week', 'is_weekend', 'is_festival']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "holiday_df = holiday_df.join(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "holiday_df.drop('holiday', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holiday_df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 添加日期特征至训练集 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.join(holiday_df, on='record_date')\n",
    "predict = predict.join(holiday_df, on='predict_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for date_span in time_spans:\n",
    "    predict = extract_post_day_describe(\n",
    "        date_span,\n",
    "        train,\n",
    "        predict,\n",
    "        use_holiday_fetures,\n",
    "        add_feture=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 假期平均统计特征 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_describe_day_sum(group):\n",
    "    df = group.groupby('record_date')[['power_consumption']].sum().describe().unstack()['power_consumption']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_day_consumption_describe(span, f, train, predict, add_dt_feture=False):\n",
    "    tdf = get_train_df(span, train)\n",
    "    if add_dt_feture:\n",
    "        add_feture_in_date([f], predict, tdf)\n",
    "    name_fmt = 'post{}_{}_{}_day_consumption'\n",
    "    df = tdf.groupby(f).apply(apply_describe_day_sum)\n",
    "    df.columns = [name_fmt.format(span, f, x) for x in df.columns]\n",
    "    predict = predict.join(df, on=f)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract_day_consumption_describe(30, 'is_week', train, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in use_holiday_fetures:\n",
    "    for span in time_spans:\n",
    "        if f != 'is_weekend':  # compelete same with is_week\n",
    "            predict = extract_day_consumption_describe(span, f, train, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总数统计特征 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "used_sum_fetures = [\n",
    "    'dayofweek', 'dayofyear', 'days_in_month', \n",
    "    'quarter', 'week', \n",
    "    'month', 'year'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_mean_consumption(train_df, feture, date_span, predict, div_times):\n",
    "    column_fmt = 'post{}_{}_mean_consumption'\n",
    "    df = train_df.groupby(feture)['power_consumption'].sum() / (date_span / div_times)\n",
    "    df.name = column_fmt.format(date_span, feture)\n",
    "    predict = predict.join(df)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_post_mean_consumption(feture, div_times, date_span, train, predict):\n",
    "    train_df = get_train_df(30, train)\n",
    "    add_feture_in_date(used_sum_fetures, predict, train_df)\n",
    "    predict = extract_mean_consumption(train_df, feture, date_span, predict, div_times)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_all_post_mean_consumption(used_sum_feture_model, train, predict):   \n",
    "    for feture, div_times, date_spans in used_sum_feture_model:\n",
    "        for date_span in date_spans:\n",
    "            predict = extract_post_mean_consumption(feture, div_times, date_span, train, predict)\n",
    "    return predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "used_sum_feture_model = [\n",
    "    ('dayofweek', 7, [30, 60, 90, 180, 360]),\n",
    "    ('dayofyear', 1, [30, 60, 90, 180, 360]),\n",
    "    ('days_in_month', 30, [30, 60, 90, 180, 360]),\n",
    "    ('quarter', 90, [90, 180, 360]),\n",
    "    ('week', 52, [180, 360]),\n",
    "    ('month', 30, [30, 60, 90, 120, 240, 360]),\n",
    "    ('year', 360, [ 360]), \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict = extract_all_post_mean_consumption(used_sum_feture_model, train, predict)  # over fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract_day_consumption_describe(30, 'dayofweek', train, predict, add_dt_feture=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in used_sum_fetures:\n",
    "    for span in time_spans:\n",
    "        predict = extract_day_consumption_describe(span, f, train, predict, add_dt_feture=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 天气特征 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header = ['weather_date', 'weather_max', 'weather_min', 'weather_type', 'weather_wind', 'wind_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weather_date</th>\n",
       "      <th>weather_max</th>\n",
       "      <th>weather_min</th>\n",
       "      <th>weather_type</th>\n",
       "      <th>weather_wind</th>\n",
       "      <th>wind_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>8</td>\n",
       "      <td>-4</td>\n",
       "      <td>晴</td>\n",
       "      <td>西南风</td>\n",
       "      <td>小于3级</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>多云转晴</td>\n",
       "      <td>东南风</td>\n",
       "      <td>小于3级</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>多云</td>\n",
       "      <td>南风</td>\n",
       "      <td>小于3级</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  weather_date  weather_max  weather_min weather_type weather_wind wind_type\n",
       "0   2015-01-01            8           -4            晴          西南风      小于3级\n",
       "1   2015-01-02           13            0         多云转晴          东南风      小于3级\n",
       "2   2015-01-03           16            3           多云           南风      小于3级"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = pd.read_csv('../dataset/yangzhong.csv', header=None, names=header, parse_dates=['weather_date'])\n",
    "weather_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将天气切分成块,再提取块边界 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_df.weather_min = pd.cut(weather_df.weather_min, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhanglun/.pyenv/versions/anaconda3-4.1.0/lib/python3.5/site-packages/ipykernel/__main__.py:1: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "weather_df.weather_min = weather_df.weather_min.str.extract('\\((-?\\d+\\.?\\d*),').astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_df.weather_max = pd.cut(weather_df.weather_max, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhanglun/.pyenv/versions/anaconda3-4.1.0/lib/python3.5/site-packages/ipykernel/__main__.py:1: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "weather_df.weather_max = weather_df.weather_max.str.extract(', (-?\\d+\\.?\\d*)\\]').astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(731, 6)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_type_count = weather_df.weather_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_df.weather_type = weather_df.weather_type.replace([\n",
    "    x for x in weather_type_count.loc[weather_type_count < 2].index\n",
    "], 'rare_weather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_df.loc[weather_df.weather_type.str.contains('阵雨'), 'weather_type'] = 'showers_weather'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_df.loc[weather_df.weather_type.str.contains('雨'), 'weather_type'] = 'rain_weather'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_df.loc[~weather_df.weather_type.str.islower(), 'weather_type'] = 'fine_weather'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_df = weather_df.join(pd.get_dummies(weather_df.weather_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_num_columns = [\n",
    "    'weather_max', 'weather_min', 'wind_type', 'fine_weather', 'rain_weather',\n",
    "    'rare_weather', 'showers_weather'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weather_date</th>\n",
       "      <th>weather_max</th>\n",
       "      <th>weather_min</th>\n",
       "      <th>weather_type</th>\n",
       "      <th>weather_wind</th>\n",
       "      <th>wind_type</th>\n",
       "      <th>fine_weather</th>\n",
       "      <th>rain_weather</th>\n",
       "      <th>rare_weather</th>\n",
       "      <th>showers_weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>fine_weather</td>\n",
       "      <td>西南风</td>\n",
       "      <td>小于3级</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>16.5</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>fine_weather</td>\n",
       "      <td>东南风</td>\n",
       "      <td>小于3级</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>16.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>fine_weather</td>\n",
       "      <td>南风</td>\n",
       "      <td>小于3级</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>16.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rare_weather</td>\n",
       "      <td>东风</td>\n",
       "      <td>3-4级</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rare_weather</td>\n",
       "      <td>西北风</td>\n",
       "      <td>4-5级转3-4级</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  weather_date  weather_max  weather_min  weather_type weather_wind  \\\n",
       "0   2015-01-01         12.0         -6.0  fine_weather          西南风   \n",
       "1   2015-01-02         16.5         -2.0  fine_weather          东南风   \n",
       "2   2015-01-03         16.5          2.0  fine_weather           南风   \n",
       "3   2015-01-04         16.5          2.0  rare_weather           东风   \n",
       "4   2015-01-05         12.0         -2.0  rare_weather          西北风   \n",
       "\n",
       "   wind_type  fine_weather  rain_weather  rare_weather  showers_weather  \n",
       "0       小于3级           1.0           0.0           0.0              0.0  \n",
       "1       小于3级           1.0           0.0           0.0              0.0  \n",
       "2       小于3级           1.0           0.0           0.0              0.0  \n",
       "3       3-4级           0.0           0.0           1.0              0.0  \n",
       "4  4-5级转3-4级           0.0           0.0           1.0              0.0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_df.weather_wind.replace('东南风', 'southeast_wind', inplace=True)\n",
    "weather_df.weather_wind.replace('东北风', 'northeast_wind', inplace=True)\n",
    "weather_df.weather_wind.replace('西南风', 'southwest_wind', inplace=True)\n",
    "weather_df.weather_wind.replace('西北风', 'northwest_wind', inplace=True)\n",
    "weather_df.weather_wind.replace('东风', 'east_wind', inplace=True)\n",
    "weather_df.weather_wind.replace('北风', 'north_wind', inplace=True)\n",
    "weather_df.weather_wind.replace('南风', 'south_wind', inplace=True)\n",
    "weather_df.weather_wind.replace('西风', 'west_wind', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_df.weather_wind.replace(['3-4级', '暂无实况', '无持续风向'], 'unknow_wind', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_df = weather_df.join(pd.get_dummies(weather_df.weather_wind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wind_type_count = weather_df.wind_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_df.wind_type = weather_df.wind_type.replace([\n",
    "    x for x in wind_type_count.loc[wind_type_count < 5 ].index\n",
    "], 'rare_wind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_df.wind_type.replace('rare_wind', 0, inplace=True)\n",
    "weather_df.wind_type.replace('微风', 1, inplace=True)\n",
    "weather_df.wind_type.replace('1级', 2, inplace=True)\n",
    "weather_df.wind_type.replace('2级', 3, inplace=True)\n",
    "weather_df.wind_type.replace('小于3级', 4, inplace=True)\n",
    "weather_df.wind_type.replace('3级', 6, inplace=True)\n",
    "weather_df.wind_type.replace('3-4级转小于3级', 5, inplace=True)\n",
    "weather_df.wind_type.replace('3-4级', 7, inplace=True)\n",
    "weather_df.wind_type.replace('4-5级转3-4级', 8, inplace=True)\n",
    "weather_df.wind_type.replace('4-5级', 9, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0    482\n",
       "3.0     69\n",
       "4.0     58\n",
       "2.0     42\n",
       "6.0     27\n",
       "0.0     16\n",
       "1.0     10\n",
       "8.0      8\n",
       "9.0      7\n",
       "5.0      5\n",
       "Name: wind_type, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.wind_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weather_date</th>\n",
       "      <th>weather_max</th>\n",
       "      <th>weather_min</th>\n",
       "      <th>weather_type</th>\n",
       "      <th>weather_wind</th>\n",
       "      <th>wind_type</th>\n",
       "      <th>fine_weather</th>\n",
       "      <th>rain_weather</th>\n",
       "      <th>rare_weather</th>\n",
       "      <th>showers_weather</th>\n",
       "      <th>east_wind</th>\n",
       "      <th>north_wind</th>\n",
       "      <th>northeast_wind</th>\n",
       "      <th>northwest_wind</th>\n",
       "      <th>south_wind</th>\n",
       "      <th>southeast_wind</th>\n",
       "      <th>southwest_wind</th>\n",
       "      <th>unknow_wind</th>\n",
       "      <th>west_wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>fine_weather</td>\n",
       "      <td>southwest_wind</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>16.5</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>fine_weather</td>\n",
       "      <td>southeast_wind</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>16.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>fine_weather</td>\n",
       "      <td>south_wind</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>16.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rare_weather</td>\n",
       "      <td>east_wind</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rare_weather</td>\n",
       "      <td>northwest_wind</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  weather_date  weather_max  weather_min  weather_type    weather_wind  \\\n",
       "0   2015-01-01         12.0         -6.0  fine_weather  southwest_wind   \n",
       "1   2015-01-02         16.5         -2.0  fine_weather  southeast_wind   \n",
       "2   2015-01-03         16.5          2.0  fine_weather      south_wind   \n",
       "3   2015-01-04         16.5          2.0  rare_weather       east_wind   \n",
       "4   2015-01-05         12.0         -2.0  rare_weather  northwest_wind   \n",
       "\n",
       "   wind_type  fine_weather  rain_weather  rare_weather  showers_weather  \\\n",
       "0        4.0           1.0           0.0           0.0              0.0   \n",
       "1        4.0           1.0           0.0           0.0              0.0   \n",
       "2        4.0           1.0           0.0           0.0              0.0   \n",
       "3        7.0           0.0           0.0           1.0              0.0   \n",
       "4        8.0           0.0           0.0           1.0              0.0   \n",
       "\n",
       "   east_wind  north_wind  northeast_wind  northwest_wind  south_wind  \\\n",
       "0        0.0         0.0             0.0             0.0         0.0   \n",
       "1        0.0         0.0             0.0             0.0         0.0   \n",
       "2        0.0         0.0             0.0             0.0         1.0   \n",
       "3        1.0         0.0             0.0             0.0         0.0   \n",
       "4        0.0         0.0             0.0             1.0         0.0   \n",
       "\n",
       "   southeast_wind  southwest_wind  unknow_wind  west_wind  \n",
       "0             0.0             1.0          0.0        0.0  \n",
       "1             1.0             0.0          0.0        0.0  \n",
       "2             0.0             0.0          0.0        0.0  \n",
       "3             0.0             0.0          0.0        0.0  \n",
       "4             0.0             0.0          0.0        0.0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.join(weather_df.set_index('weather_date'), on='record_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict = predict.join(weather_df.set_index('weather_date'), on='predict_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 添加天气特征(超前) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_weather_fetures = ['weather_max', 'weather_min', 'weather_type', 'weather_wind', 'wind_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhanglun/.pyenv/versions/anaconda3-4.1.0/lib/python3.5/site-packages/numpy/lib/function_base.py:3823: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "for date_span in time_spans:\n",
    "    predict = extract_post_day_describe(\n",
    "        date_span,\n",
    "        train,\n",
    "        predict,\n",
    "        use_weather_fetures,\n",
    "        add_feture=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract_day_consumption_describe(30, 'weather_max', train, predict, add_dt_feture=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in use_weather_fetures:\n",
    "    for span in time_spans:\n",
    "        predict = extract_day_consumption_describe(span, f, train, predict, add_dt_feture=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交叉特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  时间 X 假期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_combin_feture_day_consumption_describe(span, f1, f2, predict, train, f1_need_add=True, f2_need_add=False):\n",
    "    tdf = get_train_df(span, train)\n",
    "    if f1_need_add:\n",
    "        add_feture_in_date([f1], predict, tdf)\n",
    "    if f2_need_add:\n",
    "        add_feture_in_date([f2], predict, tdf) \n",
    "    new_feture_name = 'post{}_combine_{}_and_{}'.format(span, f1, f2)\n",
    "    predict[new_feture_name] = predict[f1] * predict[f2]\n",
    "    tdf[new_feture_name] = tdf[f1] * tdf[f2]\n",
    "    predict = extract_day_consumption_describe(span, new_feture_name, tdf, predict)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract_combin_feture_day_consumption_describe(30, 'dayofweek', 'is_week', predict, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for span in time_spans:\n",
    "    for f1 in used_data_fetures:\n",
    "        for f2 in use_holiday_fetures:\n",
    "            predict = extract_combin_feture_day_consumption_describe(span, f1, f2, predict, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 时间 X 天气 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for span in time_spans:\n",
    "    for f1 in used_data_fetures:\n",
    "        for f2 in weather_num_columns:\n",
    "            predict = extract_combin_feture_day_consumption_describe(span, f1, f2, predict, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 天气 X 假期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for span in time_spans:\n",
    "    for f1 in weather_num_columns:\n",
    "        for f2 in use_holiday_fetures:\n",
    "            predict = extract_combin_feture_day_consumption_describe(span, f1, f2, predict, train, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not_use_columns = ['weather_type', 'weather_wind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_feture_not_use = [x for x in used_data_fetures if  x.startswith('is_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feture_columns = [x for x in predict.columns if x not in not_use_columns ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feture_columns = [x for x in feture_columns if x not in use_weather_fetures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feture_columns = [x for x in feture_columns if x not in use_holiday_fetures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'weather_max' in feture_columns, 'is_week' in feture_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict.to_csv(feture_path, columns=feture_columns, index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
